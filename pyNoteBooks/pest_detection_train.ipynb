{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8322d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rtlmhjbn/ip02-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom Dataset for IP102\n",
    "class IP102Dataset(Dataset):\n",
    "    def __init__(self, data_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(data_file, sep=' ', header=None, names=['image', 'label'])\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, str(self.data.iloc[idx, 1]), self.data.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.data.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Load class names from classes.txt\n",
    "def load_class_names(classes_file):\n",
    "    try:\n",
    "        with open(classes_file, 'r') as f:\n",
    "            classes = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n",
    "        return classes\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading classes.txt: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f\"Validation Acc: {val_acc:.2f}%\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'resnet50_ip102.pth')\n",
    "\n",
    "# Testing function\n",
    "def test_model(model, test_loader, class_names):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "def main():\n",
    "    # Paths (update these based on your setup)\n",
    "    data_dir = \"/root/.cache/kagglehub/datasets/rtlmhjbn/ip02-dataset/versions/1/classification\"  # Update with path to classification directory\n",
    "    classes_file = \"/root/.cache/kagglehub/datasets/rtlmhjbn/ip02-dataset/versions/1/classes.txt\"  # Update with path to classes.txt\n",
    "    train_file = \"/root/.cache/kagglehub/datasets/rtlmhjbn/ip02-dataset/versions/1/train.txt\"\n",
    "    test_file = \"/root/.cache/kagglehub/datasets/rtlmhjbn/ip02-dataset/versions/1/test.txt\"\n",
    "    valid_file = \"/root/.cache/kagglehub/datasets/rtlmhjbn/ip02-dataset/versions/1/val.txt\"\n",
    "\n",
    "    # Validate paths\n",
    "    for path in [data_dir, classes_file, train_file, test_file, valid_file]:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Error: {path} does not exist.\")\n",
    "            return\n",
    "\n",
    "    # Load class names\n",
    "    class_names = load_class_names(classes_file)\n",
    "    if class_names is None:\n",
    "        return\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = IP102Dataset(train_file, os.path.join(data_dir, 'train'), transform=train_transform)\n",
    "    val_dataset = IP102Dataset(valid_file, os.path.join(data_dir, 'val'), transform=val_test_transform)\n",
    "    test_dataset = IP102Dataset(test_file, os.path.join(data_dir, 'test'), transform=val_test_transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Initialize model\n",
    "    model = models.resnet50(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    # Train and validate\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1)\n",
    "\n",
    "    # Test\n",
    "    test_model(model, test_loader, class_names)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
